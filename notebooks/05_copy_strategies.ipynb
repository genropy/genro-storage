{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Copy Strategies and Filtering\n",
    "\n",
    "**Duration:** 25 minutes  \n",
    "**Level:** Intermediate\n",
    "\n",
    "Learn how to copy files efficiently with skip strategies and filtering.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Skip strategies (never, exists, size, hash)\n",
    "- Custom skip functions\n",
    "- File filtering (include/exclude patterns)\n",
    "- Progress tracking and callbacks\n",
    "- Incremental backups\n",
    "- Performance optimization\n",
    "\n",
    "## Why Skip Strategies?\n",
    "\n",
    "Copying can be expensive (time, bandwidth, cost). Skip strategies let you:\n",
    "- Avoid copying unchanged files\n",
    "- Save time and bandwidth\n",
    "- Implement incremental backups\n",
    "- Reduce cloud storage costs\n",
    "\n",
    "Let's optimize! âš¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genro_storage import StorageManager\n",
    "import time\n",
    "\n",
    "storage = StorageManager()\n",
    "storage.configure([\n",
    "    {'name': 'source', 'type': 'memory'},\n",
    "    {'name': 'dest', 'type': 'memory'}\n",
    "])\n",
    "\n",
    "print(\"âœ“ Storage ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Default Behavior (skip='never')\n",
    "\n",
    "By default, copy always overwrites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create source file\nsrc = storage.node('source:file.txt')\nsrc.write('Version 1')\n\n# Copy once\ndst = storage.node('dest:file.txt')\nsrc.copy_to(dst)\nprint(f\"First copy: {dst.read()}\")\n\n# Modify source and copy again\nsrc.write('Version 2')\nsrc.copy_to(dst)  # Overwrites even though dst exists\nprint(f\"Second copy: {dst.read()}\")\n\nprint(\"\\nâœ“ Default behavior: always overwrite\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Skip Strategy: 'exists'\n",
    "\n",
    "Skip if destination exists (fastest):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create files\nsrc1 = storage.node('source:new_file.txt')\nsrc1.write('New content')\n\nsrc2 = storage.node('source:existing_file.txt')\nsrc2.write('Will be skipped')\n\ndst2 = storage.node('dest:existing_file.txt')\ndst2.write('Already exists')\n\n# Copy with skip='exists'\nprint(\"Copying with skip='exists':\")\n\nresult1 = src1.copy_to(storage.node('dest:new_file.txt'), skip='exists')\nprint(f\"  new_file: copied\")\n\nresult2 = src2.copy_to(dst2, skip='exists')\nprint(f\"  existing_file: skipped\")\n\nprint(f\"\\nDestination content: {dst2.read()}\")\nprint(\"âœ“ Existing file was not overwritten\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Skip Strategy: 'size'\n",
    "\n",
    "Skip if file exists AND size matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Files with same size\nsrc_a = storage.node('source:a.txt')\nsrc_a.write('12345')  # 5 bytes\n\ndst_a = storage.node('dest:a.txt')\ndst_a.write('ABCDE')  # 5 bytes, different content\n\n# Files with different size\nsrc_b = storage.node('source:b.txt')\nsrc_b.write('123456')  # 6 bytes\n\ndst_b = storage.node('dest:b.txt')\ndst_b.write('ABC')  # 3 bytes\n\nprint(\"Copying with skip='size':\")\n\nsrc_a.copy_to(dst_a, skip='size')\nprint(f\"  a.txt: skipped (same size)\")\nprint(f\"    Content still: {dst_a.read()}\")\n\nsrc_b.copy_to(dst_b, skip='size')\nprint(f\"  b.txt: copied (different size)\")\nprint(f\"    Content now: {dst_b.read()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Skip Strategy: 'hash'\n",
    "\n",
    "Skip if file exists AND MD5 hash matches (slowest but safest):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Files with same content\nsrc_same = storage.node('source:same.txt')\nsrc_same.write('Identical content')\n\ndst_same = storage.node('dest:same.txt')\ndst_same.write('Identical content')\n\n# Files with different content\nsrc_diff = storage.node('source:diff.txt')\nsrc_diff.write('New content')\n\ndst_diff = storage.node('dest:diff.txt')\ndst_diff.write('Old content')\n\nprint(\"Copying with skip='hash':\")\n\nsrc_same.copy_to(dst_same, skip='hash')\nprint(f\"  same.txt: skipped (MD5 match)\")\n\nsrc_diff.copy_to(dst_diff, skip='hash')\nprint(f\"  diff.txt: copied (MD5 mismatch)\")\nprint(f\"    New content: {dst_diff.read()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Skip Functions\n",
    "\n",
    "Write your own skip logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def skip_if_recent(source, dest):\n    \"\"\"Skip if destination was modified in last 5 seconds\"\"\"\n    if not dest.exists:\n        return False  # Don't skip, dest doesn't exist\n    \n    age = time.time() - dest.mtime\n    return age < 5  # Skip if less than 5 seconds old\n\n# Create old file\nold_file = storage.node('dest:old.txt')\nold_file.write('Old')\ntime.sleep(0.1)  # Make it \"old\"\n\n# Create recent file\nrecent_file = storage.node('dest:recent.txt')\nrecent_file.write('Recent')\n\n# Try to copy\nsrc = storage.node('source:update.txt')\nsrc.write('Updated content')\n\nprint(\"Copying with custom skip function:\")\n\nsrc.copy_to(old_file, skip=skip_if_recent)\nprint(f\"  old.txt: copied (too old)\")\nprint(f\"    Content: {old_file.read()}\")\n\nsrc.copy_to(recent_file, skip=skip_if_recent)\nprint(f\"  recent.txt: skipped (too recent)\")\nprint(f\"    Content: {recent_file.read()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Directory Copy with Skip\n",
    "\n",
    "Apply skip strategy to entire directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create source directory\nsrc_dir = storage.node('source:project')\nsrc_dir.mkdir()\nsrc_dir.child('file1.txt').write('Content 1')\nsrc_dir.child('file2.txt').write('Content 2')\nsrc_dir.child('file3.txt').write('Content 3')\n\n# First backup\nbackup1 = storage.node('dest:backup1')\nsrc_dir.copy_to(backup1)\nprint(f\"âœ“ First backup: {len(list(backup1.children()))} files\")\n\n# Modify one file\nsrc_dir.child('file2.txt').write('Modified content 2')\n\n# Incremental backup with hash skip\nbackup2 = storage.node('dest:backup2')\nsrc_dir.copy_to(backup2, skip='hash')\n\nprint(f\"âœ“ Second backup: only changed files copied\")\nprint(f\"  file1.txt: {backup2.child('file1.txt').read()}\")\nprint(f\"  file2.txt: {backup2.child('file2.txt').read()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Progress Tracking\n",
    "\n",
    "Monitor copy operations with callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source with multiple files\n",
    "data_dir = storage.node('source:data')\n",
    "data_dir.mkdir()\n",
    "\n",
    "for i in range(10):\n",
    "    data_dir.child(f'file_{i}.txt').write_text(f'Data {i}')\n",
    "\n",
    "# Progress callback\n",
    "copied_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "def on_file_copied(src, dst):\n",
    "    global copied_count\n",
    "    copied_count += 1\n",
    "    print(f\"  âœ“ Copied: {src.basename}\")\n",
    "\n",
    "def on_file_skipped(src, dst):\n",
    "    global skipped_count\n",
    "    skipped_count += 1\n",
    "    print(f\"  âŠ˜ Skipped: {src.basename}\")\n",
    "\n",
    "# Copy with callbacks\n",
    "backup_dir = storage.node('dest:data_backup')\n",
    "print(\"First copy:\")\n",
    "data_dir.copy_to(backup_dir, on_file=on_file_copied)\n",
    "\n",
    "print(f\"\\nSecond copy (with skip='exists'):\")\n",
    "copied_count = 0\n",
    "skipped_count = 0\n",
    "data_dir.copy_to(backup_dir, skip='exists', \n",
    "              on_file=on_file_copied,\n",
    "              on_skip=on_file_skipped)\n",
    "\n",
    "print(f\"\\nSummary: {copied_count} copied, {skipped_count} skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. File Filtering: Include Patterns\n",
    "\n",
    "Copy only specific file types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mixed directory\n",
    "mixed_dir = storage.node('source:mixed')\n",
    "mixed_dir.mkdir()\n",
    "\n",
    "mixed_dir.child('doc1.txt').write_text('Text 1')\n",
    "mixed_dir.child('doc2.txt').write_text('Text 2')\n",
    "mixed_dir.child('image1.jpg').write_text('JPG data')\n",
    "mixed_dir.child('image2.png').write_text('PNG data')\n",
    "mixed_dir.child('video.mp4').write_text('Video data')\n",
    "\n",
    "# Copy only text files\n",
    "text_backup = storage.node('dest:text_only')\n",
    "mixed_dir.copy_to(text_backup, include=['*.txt'])\n",
    "\n",
    "print(\"Text-only backup contains:\")\n",
    "for child in text_backup.children():\n",
    "    print(f\"  - {child.basename}\")\n",
    "\n",
    "# Copy only images\n",
    "image_backup = storage.node('dest:images_only')\n",
    "mixed_dir.copy_to(image_backup, include=['*.jpg', '*.png'])\n",
    "\n",
    "print(\"\\nImage-only backup contains:\")\n",
    "for child in image_backup.children():\n",
    "    print(f\"  - {child.basename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. File Filtering: Exclude Patterns\n",
    "\n",
    "Skip specific files or patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create project directory\n",
    "project = storage.node('source:myproject')\n",
    "project.mkdir()\n",
    "\n",
    "project.child('main.py').write_text('# Main')\n",
    "project.child('utils.py').write_text('# Utils')\n",
    "project.child('.env').write_text('SECRET=xxx')\n",
    "project.child('.gitignore').write_text('*.pyc')\n",
    "project.child('__pycache__').mkdir()\n",
    "project.child('README.md').write_text('# Project')\n",
    "\n",
    "# Copy excluding hidden and cache files\n",
    "clean_copy = storage.node('dest:clean_project')\n",
    "project.copy_to(clean_copy, exclude=['.*', '__pycache__'])\n",
    "\n",
    "print(\"Clean copy contains:\")\n",
    "for child in clean_copy.children():\n",
    "    print(f\"  - {child.basename}\")\n",
    "print(\"\\nâœ“ Hidden files and cache excluded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Combining Include and Exclude\n",
    "\n",
    "Use both for fine-grained control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complex directory\n",
    "docs = storage.node('source:documents')\n",
    "docs.mkdir()\n",
    "\n",
    "docs.child('report.pdf').write_text('PDF')\n",
    "docs.child('draft.pdf').write_text('Draft PDF')\n",
    "docs.child('notes.txt').write_text('Notes')\n",
    "docs.child('draft.txt').write_text('Draft notes')\n",
    "docs.child('data.csv').write_text('CSV')\n",
    "\n",
    "# Copy only PDFs and TXTs, but exclude drafts\n",
    "final_docs = storage.node('dest:final_documents')\n",
    "docs.copy_to(final_docs, \n",
    "          include=['*.pdf', '*.txt'],\n",
    "          exclude=['draft.*'])\n",
    "\n",
    "print(\"Final documents:\")\n",
    "for child in final_docs.children():\n",
    "    print(f\"  - {child.basename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Custom Filter Functions\n",
    "\n",
    "Filter based on any criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_small_files(node):\n",
    "    \"\"\"Only include files smaller than 20 bytes\"\"\"\n",
    "    if node.isdir:\n",
    "        return True  # Include directories\n",
    "    return node.size < 20\n",
    "\n",
    "# Create files of various sizes\n",
    "sized_dir = storage.node('source:sized')\n",
    "sized_dir.mkdir()\n",
    "\n",
    "sized_dir.child('small.txt').write_text('small')  # 5 bytes\n",
    "sized_dir.child('medium.txt').write_text('medium content here')  # 19 bytes\n",
    "sized_dir.child('large.txt').write_text('large content here with more text')  # 35 bytes\n",
    "\n",
    "# Copy with size filter\n",
    "small_only = storage.node('dest:small_files')\n",
    "sized_dir.copy_to(small_only, filter=filter_small_files)\n",
    "\n",
    "print(\"Small files only:\")\n",
    "for child in small_only.children():\n",
    "    print(f\"  - {child.basename} ({child.size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Performance Comparison\n",
    "\n",
    "Compare different skip strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create test data\n",
    "test_dir = storage.node('source:perf_test')\n",
    "test_dir.mkdir()\n",
    "\n",
    "for i in range(50):\n",
    "    test_dir.child(f'file_{i}.txt').write_text(f'Content {i}' * 10)\n",
    "\n",
    "# Initial copy\n",
    "dest_dir = storage.node('dest:perf_test')\n",
    "test_dir.copy_to(dest_dir)\n",
    "\n",
    "# Modify one file\n",
    "test_dir.child('file_25.txt').write_text('Modified!')\n",
    "\n",
    "# Test different strategies\n",
    "strategies = ['never', 'exists', 'size', 'hash']\n",
    "results = {}\n",
    "\n",
    "for strategy in strategies:\n",
    "    start = time.time()\n",
    "    test_dir.copy_to(dest_dir, skip=strategy)\n",
    "    elapsed = time.time() - start\n",
    "    results[strategy] = elapsed\n",
    "\n",
    "print(\"Performance comparison (50 files, 1 changed):\")\n",
    "for strategy, elapsed in results.items():\n",
    "    print(f\"  {strategy:10s}: {elapsed*1000:.2f}ms\")\n",
    "\n",
    "print(f\"\\nâœ“ 'exists' is typically fastest for skip scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Incremental Backup Pattern\n",
    "\n",
    "A complete incremental backup implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_backup(source_dir, backup_dir, strategy='hash'):\n",
    "    \"\"\"Perform incremental backup with statistics\"\"\"\n",
    "    stats = {\n",
    "        'copied': 0,\n",
    "        'skipped': 0,\n",
    "        'bytes_copied': 0,\n",
    "        'bytes_skipped': 0\n",
    "    }\n",
    "    \n",
    "    def on_copy(src, dst):\n",
    "        stats['copied'] += 1\n",
    "        stats['bytes_copied'] += src.size\n",
    "        \n",
    "    def on_skip(src, dst):\n",
    "        stats['skipped'] += 1\n",
    "        stats['bytes_skipped'] += src.size\n",
    "    \n",
    "    source_dir.copy_to(backup_dir, \n",
    "                   skip=strategy,\n",
    "                   on_file=on_copy,\n",
    "                   on_skip=on_skip)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Create data\n",
    "data = storage.node('source:important_data')\n",
    "data.mkdir()\n",
    "for i in range(20):\n",
    "    data.child(f'data_{i}.txt').write_text(f'Important data {i}' * 5)\n",
    "\n",
    "# First backup\n",
    "backup = storage.node('dest:backup')\n",
    "print(\"First backup:\")\n",
    "stats1 = incremental_backup(data, backup, 'hash')\n",
    "print(f\"  Copied: {stats1['copied']} files, {stats1['bytes_copied']} bytes\")\n",
    "\n",
    "# Modify some files\n",
    "data.child('data_5.txt').write_text('Modified')\n",
    "data.child('data_10.txt').write_text('Modified')\n",
    "\n",
    "# Incremental backup\n",
    "print(\"\\nIncremental backup:\")\n",
    "stats2 = incremental_backup(data, backup, 'hash')\n",
    "print(f\"  Copied: {stats2['copied']} files, {stats2['bytes_copied']} bytes\")\n",
    "print(f\"  Skipped: {stats2['skipped']} files, {stats2['bytes_skipped']} bytes\")\n",
    "print(f\"\\nâœ“ Saved {stats2['bytes_skipped']} bytes by skipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Try It Yourself! ðŸŽ¯\n",
    "\n",
    "**Exercise 1:** Create a sync function that copies new/modified files and deletes removed ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_directories(source, dest):\n",
    "    \"\"\"\n",
    "    Sync source to dest:\n",
    "    - Copy new/modified files\n",
    "    - Delete files not in source\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Implement a smart backup that keeps only last N versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotating_backup(source_dir, backup_base, max_versions=3):\n",
    "    \"\"\"\n",
    "    Create timestamped backup and keep only last N versions.\n",
    "    backup_base/2024-01-15_10-30/\n",
    "    backup_base/2024-01-15_14-20/\n",
    "    etc.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Create a deduplication function using hash comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(directory):\n",
    "    \"\"\"\n",
    "    Find duplicate files in directory by hash.\n",
    "    Return dict: {hash: [node1, node2, ...]}\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've mastered copy optimization:\n",
    "\n",
    "- âœ“ Skip strategies (never, exists, size, hash)\n",
    "- âœ“ Custom skip functions\n",
    "- âœ“ File filtering (include/exclude)\n",
    "- âœ“ Progress tracking with callbacks\n",
    "- âœ“ Custom filter functions\n",
    "- âœ“ Performance considerations\n",
    "- âœ“ Incremental backup patterns\n",
    "\n",
    "## Skip Strategy Guide\n",
    "\n",
    "| Strategy | Speed | Safety | Use When |\n",
    "|----------|-------|--------|----------|\n",
    "| `never` | Fast | N/A | Always overwrite |\n",
    "| `exists` | Fastest | Low | First-time sync |\n",
    "| `size` | Fast | Medium | Quick incremental |\n",
    "| `hash` | Slow | High | Critical data |\n",
    "| Custom | Varies | Custom | Special logic |\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "- **Development**: Use `exists` for speed\n",
    "- **Production**: Use `size` for balance\n",
    "- **Critical data**: Use `hash` for correctness\n",
    "- **Monitor**: Always use callbacks for large operations\n",
    "- **Filter**: Exclude unnecessary files early\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "Continue to:\n",
    "\n",
    "- **[06_versioning.ipynb](06_versioning.ipynb)** - S3 versioning features\n",
    "- **[07_advanced_features.ipynb](07_advanced_features.ipynb)** - Advanced integrations\n",
    "\n",
    "Happy optimizing! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}